{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "7564t6l2fxksy64ip6dl",
   "authorId": "8092773048432",
   "authorName": "NWBURTON",
   "authorEmail": "burton.n.w@wustl.edu",
   "sessionId": "e7fde1ea-cccc-4018-a488-a84d3c676431",
   "lastEditTime": 1759291079596
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ecc5997-d95e-45f5-a1fc-ce2325adb0c6",
   "metadata": {
    "name": "Sec01",
    "collapsed": false
   },
   "source": "**Section 1: Multiple Regression**\n\nA healthcare non-profit is interested in understanding the impact of statewide demographic information and cigarette prices on cigarette sales. They feel that if any of these factors are significantly related to cigarette sales, it will help them figure out which areas should be targeted with anti-smoking messaging.\n\n    1. Answer the following:\n        a. What is the outcome?\n        b. What are the predictors they want to understand the impact of?\n        c. What is the hypothesis?"
  },
  {
   "cell_type": "markdown",
   "id": "9a977e2f-100a-4162-a3e1-0bdc8191f87a",
   "metadata": {
    "name": "Sec01_01_Resp",
    "collapsed": false
   },
   "source": "    a. We are trying to explain the sales of cigarettes based on a number of predictors, so the outcome is Sales.\n    b. The predictors are all of the demographic data and the price of cigarettes. Age, HS, Income, Black, Female, and Price\n    c. The hypothesis is that in independent variables influence the total sales of cigarettes. Specifically, I hypothesize that increased price leads to decreased sales, and the other factors influence sales either positively or negatively."
  },
  {
   "cell_type": "code",
   "id": "57d8f262-b433-48c5-b07d-cd50ee0a2efb",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport altair as alt\nimport statsmodels.api as sm\n\ncig_sales = pd.read_csv(\"cigarette_sales.csv\")\nprint(cig_sales.head())\ncig_sales.describe()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "33f8b2f7-0c0d-4b4d-ac90-8e0cb384631d",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": "Missing values: all columns have 51 obs, so there are no missing records in the data.\n\nSpread of the data: Income has a broad range compared to the other variables, so we will likely want to scale the data.\n\nSkew: the mean is 10% and the min/max is 0.2/71.1, so the data is very skewed.\n\nSales: The max is very high compared to the 75% value, so there may be an outlier in Sales."
  },
  {
   "cell_type": "code",
   "id": "33c14deb-b95c-4516-bc36-59f8616db515",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "sns.pairplot(cig_sales)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "303597d7-481a-43a6-aa06-22ce6d252ce3",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "Black is very skewed, so we will need to transform this. Sales has a broad spread so we probably want to transform this and find out about potential outliers."
  },
  {
   "cell_type": "code",
   "id": "24fde502-3be4-40e4-b136-2f7c47931e42",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# transform data\ncig_sales['log_sales'] = np.log(cig_sales['Sales'])\ncig_sales['log_price'] = np.log(cig_sales['Price'])\ncig_sales['log_black'] = np.log(cig_sales['Black'])\ncig_sales['log_income'] = np.log(cig_sales['Income'])\n\nsns.pairplot(cig_sales[['log_sales','log_income','log_price','log_black','Age','HS','Female']])",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9e499f81-54e9-4de3-9f8d-9ec3cc6fa69f",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "The transformed data appears to be more symmetric and better fits the assumptions of a multiple regression model."
  },
  {
   "cell_type": "code",
   "id": "8234ad20-96b9-43bb-8476-bf6c6bd8c4b8",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "sns.boxplot(x=cig_sales[\"log_sales\"])\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "72e33249-ed67-4145-8b67-09564bf5a063",
   "metadata": {
    "name": "cell10",
    "collapsed": false
   },
   "source": "There does appear to be outliers in the Sales data."
  },
  {
   "cell_type": "code",
   "id": "b776e9a7-0dc9-4f7c-aecd-a6b300648c35",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "X = cig_sales[['log_income','log_price','log_black','Age','HS','Female']]\ny = cig_sales['log_sales']\nX = sm.add_constant(X)\n\nmodel = sm.OLS(y,X)\nresults = model.fit()\nresults.summary()\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cb25e42a-68d8-4f65-8ffb-0b61a439c28a",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "Price and Income are significant, both having P-Values below the alpha, 0.05. The coefficients tell us that as income increases, smoking sales also increases, but as price decreases, sales also decrease. The intercept tells us that with everything else being at 0, the minimum sales is ~0.7, but it is not significant. This is likely because of the log transformation on the variables."
  },
  {
   "cell_type": "markdown",
   "id": "c13bc687-0cc4-4920-b38c-d60093ce15fa",
   "metadata": {
    "name": "cell12",
    "collapsed": false
   },
   "source": "**Section 2: Detecting Assumption Violations**\n\nUsing the same data set and regression results from the prior seciont, do the following:\n\n    1. Collinearity\n        a. Compute the VIF for each covariate and explain what the results mean.\n        b. Compute all the pairwise correlations between the variables.\n        c. Remove the 3 variables with the highest p-values. Refit the models, How have the other variables changed? Did R2 change by much?"
  },
  {
   "cell_type": "code",
   "id": "02c9a7fa-a972-4cb9-8ef8-0fa623071d44",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": "from patsy import dmatrices\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\ny, X = dmatrices('log_sales~log_income+log_price+log_black+Age+HS+Female',data = cig_sales, return_type='dataframe')\n\nvif = pd.DataFrame()\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['variable'] = X.columns\n\nvif",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c8298bcb-6fcd-460a-a7ff-7ffe99e18d65",
   "metadata": {
    "name": "cell14"
   },
   "source": "the VIFs here tell us that since log_income, log_black, and HS have high values (higher than 1), there is a moderate correlation between the given explanatory variables and the other explanatory variables. The closer the values are to 5, the more severe they are, but since none of them are higher than five, they likely don't require attention."
  },
  {
   "cell_type": "code",
   "id": "0c37eeca-dd62-41c1-99a4-23f76cb06462",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": "corr = cig_sales[['log_income','log_price','log_black','Age','HS','Female','log_sales']].corr()\nsns.heatmap(corr, cmap=\"coolwarm\", annot=True)\nplt.title('Correlation Heatmap')\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1f03e400-9502-474d-abbc-4a21ff9d9c79",
   "metadata": {
    "name": "cell17",
    "collapsed": false
   },
   "source": "There is a moderate positive correlation between HS and Income and between Female and Black.\n\nThere is a moderate negative correlation between Black and Hs and between HS and Female."
  },
  {
   "cell_type": "code",
   "id": "011ca6db-f940-48fe-840d-7d1e3c44826a",
   "metadata": {
    "language": "python",
    "name": "cell16",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "X = cig_sales[['log_income','log_price','Age']]\ny = cig_sales['log_sales']\nX = sm.add_constant(X)\n\nmodel = sm.OLS(y,X)\nresults = model.fit()\nresults.summary()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4b801210-baf0-4d0d-a88b-faf5311b4950",
   "metadata": {
    "name": "cell18",
    "collapsed": false
   },
   "source": "The p-values for price and income got slightly higher, but both are still very low and still significant. Age now has a lower p-value and is now significant to the model- higher age predicts higher sales. The constant is also significant now.\n\nThe R2 for the model has gotten slightly lower, from 40% to 37%, so less variance is explained by the model, although it is small.\n\nThe AIC has gotten lower for the second model, which tells us that the model now better explains the relationships between the variables in the model."
  },
  {
   "cell_type": "code",
   "id": "5313cbb3-d8db-4d75-a0a1-7c61e1b07490",
   "metadata": {
    "language": "python",
    "name": "cell19",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# fitted values\nmodel_fitted_y = results.fittedvalues\n\n#model residuals\nmodel_residuals = results.resid\n\n# normalized residuals\nmodel_norm_residuals = results.get_influence().resid_studentized_internal\n\n# absolute squared normalized residuals\nmodel_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))\n\n# absolute residuals\nmodel_abs_resid = np.abs(model_residuals)\n\n# leverage model\nmodel_leverage = results.get_influence().hat_matrix_diag\n\n# cook's distance\nmodel_cooks = results.get_influence().cooks_distance[0]\n\nplt.scatter(model_leverage, model_norm_residuals, alpha=0.5)\nsns.regplot(x = model_leverage, y = model_norm_residuals, \n            scatter=False, \n            ci=False, \n            lowess=True,\n            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n\nplt.xlim(0,0.30)\nplt.ylim(-3,5)\nplt.title('Residuals vs Leverage')\nplt.xlabel('Leverage')\nplt.ylabel('Standardized Residuals')\n\n# annotations\nleverage_top_3 = np.flip(np.argsort(model_cooks),0)[:3]\n\nfor i in leverage_top_3:\n    plt.annotate(i,\n                xy=(model_leverage[i],\n                   model_norm_residuals[i]))\n\n# shenanigans for cook's distance contours\ndef graph(formula, x_range, label=None):\n    x = x_range\n    y = formula(x)\n    plt.plot(x, y, label=label, lw=1, ls = '--', color = 'red')\n\np = len(results.params)\n\ngraph(lambda x: np.sqrt((0.5 * p * (1-x)) / x),\n     np.linspace(0.001, 0.300, 50),\n     \"Cook's distance\") # 0.5 line\ngraph(lambda x: np.sqrt((1 * p * (1-x)) / x),\n      np.linspace(0.001, 0.300, 50)) # 1 line\n\nplt.legend(loc='upper right')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "67fa93a4-c867-4397-8ea5-9e0e2efc2f02",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "There are outliers in the residuals, but it looks as though none of them are outside of cook's distance line, so they don't appear to be influential to the model."
  },
  {
   "cell_type": "code",
   "id": "39393d21-be78-4284-b8ba-43a232b34193",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": "plt.scatter(model_fitted_y, model_norm_residuals_abs_sqrt, alpha = 0.5)\nsns.regplot(x = model_fitted_y, y = model_norm_residuals_abs_sqrt,\n           scatter = False,\n           ci=False,\n           lowess = True,\n           line_kws = {'color': 'red', 'lw': 1, 'alpha': 0.8})\n\nplt.title('Scale-Location')\nplt.xlabel('Fitted values')\nplt.ylabel('$\\sqrt{|Standardized Residuals|}$')\n\n# annotations\nabs_sq_norm_resid = np.flip(np.argsort(model_norm_residuals_abs_sqrt),0)\nabs_sq_norm_resid_top_3 = abs_sq_norm_resid[:3]\n\nfor i in abs_sq_norm_resid_top_3:\n    plt.annotate(i,\n                xy=(model_fitted_y[i],\n                    model_norm_residuals_abs_sqrt[i]));",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cf3e1ff7-5ea7-41fb-87b1-aca6abba4b5b",
   "metadata": {
    "name": "cell23",
    "collapsed": false
   },
   "source": "This data likely satisfies the linearity assumption. The line appears to be reasonably flat and the residuals have a fairly uniform spread. There are a few labeled points that appear to be outliers, but we know from the prior analysis that they are not influential to the model."
  },
  {
   "cell_type": "code",
   "id": "d5cbe9dd-9175-4cb0-95aa-2055ce20db4d",
   "metadata": {
    "language": "python",
    "name": "cell20",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from statsmodels.graphics.gofplots import ProbPlot\n\nfig, ax = plt.subplots() \n\nQQ = ProbPlot(model_norm_residuals)\nQQ.qqplot(line='45', alpha=0.5, color='#4C72B0', lw=1, ax=ax)\n\n# Set title and labels on the Axes\nax.set_title('Normal Q-Q')\nax.set_xlabel('Theoretical Quantiles')\nax.set_ylabel('Standardized Residuals')\n\n# annotations\nabs_norm_resid = np.flip(np.argsort(np.abs(model_norm_residuals)), 0)\nabs_norm_resid_top_3 = abs_norm_resid[:3]\n\nfor r, i in enumerate(abs_norm_resid_top_3):\n    ax.annotate(i,\n                xy=(np.flip(QQ.theoretical_quantiles, 0)[r],\n                    model_norm_residuals[i]))\n\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f0f9dddb-2b7b-4b41-b81a-0ce65363b03d",
   "metadata": {
    "name": "cell25",
    "collapsed": false
   },
   "source": "The residuals are approximately normally distributed. There are a few deviations at the tails, but overall the residuals are normal."
  },
  {
   "cell_type": "code",
   "id": "87f71df0-3f43-434b-b5b1-276acb988aad",
   "metadata": {
    "language": "python",
    "name": "cell24",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  }
 ]
}