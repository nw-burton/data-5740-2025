{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "2r7q5hy2gtshrc2pdeno",
   "authorId": "8092773048432",
   "authorName": "NWBURTON",
   "authorEmail": "burton.n.w@wustl.edu",
   "sessionId": "6494f61e-27c7-4db5-b584-ae8034fba452",
   "lastEditTime": 1760987715935
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04148085-9ed6-4587-b59d-9996c19b09cc",
   "metadata": {
    "name": "intro",
    "collapsed": false
   },
   "source": "#### Exercise 08: Principal Component Analysis\nPick from the data in one of our previous assignments or the midterm. Conduct the same kind of PCA we did in the lab focusing only on the continuous variables.  "
  },
  {
   "cell_type": "code",
   "id": "840addee-2b7a-40db-bbb3-b1047efa79c9",
   "metadata": {
    "language": "python",
    "name": "import_packages",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e51d628f-5555-48e0-91c0-93bf69172b7b",
   "metadata": {
    "name": "num_1",
    "collapsed": false
   },
   "source": "#### 1. Explore the Data\n"
  },
  {
   "cell_type": "code",
   "id": "1b8f8ab9-a359-443e-a408-1c9b2eb989e8",
   "metadata": {
    "language": "python",
    "name": "load_data",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "construction_projects = pd.read_csv(\"midterm_construction_projects.csv\")\nconstruction_projects.describe()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93890f93-7b97-48eb-a7e6-5d30f47c989e",
   "metadata": {
    "language": "python",
    "name": "continuous_variables"
   },
   "outputs": [],
   "source": "continuous_var = construction_projects[['project_size_usd',\n                                       'scope_complexity',\n                                       'close_time_days',\n                                       'prior_relationship_years',\n                                       'discount_pct',\n                                       'pm_experience_years',\n                                       'on_time_milestones_pct',\n                                       'customer_satisfaction',\n                                       'cost_overrun_pct',\n                                       'time_overrun_pct',\n                                       'payment_delay_days',\n                                       'n_change_orders',\n                                       'next12mo_spend']].copy()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c4572c2a-0ddc-4449-a606-4a07af03fbde",
   "metadata": {
    "language": "python",
    "name": "check_for_nulls"
   },
   "outputs": [],
   "source": "continuous_var.isnull().sum()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c15d8a7e-c2a9-443e-a234-38f9b7705b3c",
   "metadata": {
    "name": "miss_vals_desc",
    "collapsed": false
   },
   "source": "There are missing values for pm_experience_years, on_time_milestones_pct, customer_satisfaction. Since discount_pct and pm_experience_years are pretty symmetrical, I will use the median. Since on_time_milestones is slightly skewed and bimodal, I will use the mean."
  },
  {
   "cell_type": "code",
   "id": "921c8389-35dc-4f12-91d5-735006be80e7",
   "metadata": {
    "language": "python",
    "name": "impute_missings"
   },
   "outputs": [],
   "source": "# impute missings\ncontinuous_var['discount_pct'] = continuous_var['discount_pct'].fillna(continuous_var['discount_pct'].median())\ncontinuous_var['pm_experience_years'] = continuous_var['pm_experience_years'].fillna(continuous_var['pm_experience_years'].median())\ncontinuous_var['on_time_milestones_pct'] = continuous_var['on_time_milestones_pct'].fillna(continuous_var['on_time_milestones_pct'].mean())\n\ncontinuous_var.describe()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ddfdcfc2-0620-443f-9bb9-7174ab088850",
   "metadata": {
    "name": "transformations_needed",
    "collapsed": false
   },
   "source": "project_size_usd is very skewed, so I will log_transform it."
  },
  {
   "cell_type": "code",
   "id": "b9c54d9c-b946-44e5-8e38-b679136f0f0c",
   "metadata": {
    "language": "python",
    "name": "log_transform",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# log transform project_size_usd\ncontinuous_var['project_size_usd'] = np.log(continuous_var['project_size_usd'])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "23dc7ee3-1946-47af-a348-96c359df789d",
   "metadata": {
    "language": "python",
    "name": "correlation"
   },
   "outputs": [],
   "source": "corr = continuous_var.corr(numeric_only=True)\ncorr",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "72ede351-4139-497d-8322-5c718299ef62",
   "metadata": {
    "name": "corr_desc",
    "collapsed": false
   },
   "source": "* cost & time overrun percent are very highly correlated with each other.\n* n_change_orders and scope complexity also have relatively high correlations."
  },
  {
   "cell_type": "markdown",
   "id": "eb04f039-b436-4eb1-aacd-89b74db83041",
   "metadata": {
    "name": "num_2",
    "collapsed": false
   },
   "source": "#### 2. Standardize the data so we can do PCA."
  },
  {
   "cell_type": "code",
   "id": "3c799a01-f894-40bb-a63e-6f03c6fc079f",
   "metadata": {
    "language": "python",
    "name": "scale_the_data",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "scaler = StandardScaler()\ncontinuous_var_scaled = scaler.fit_transform(continuous_var)\ncontinuous_var_scaled = pd.DataFrame(continuous_var_scaled)\ncontinuous_var_scaled.describe()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "79f1b953-97e9-4c30-b2fd-495ea6a5efff",
   "metadata": {
    "name": "num_3",
    "collapsed": false
   },
   "source": "#### 3. Fit PCA and look at the variance explained"
  },
  {
   "cell_type": "code",
   "id": "5c5ec32a-2f02-4d8d-b73f-49c334c71ecc",
   "metadata": {
    "language": "python",
    "name": "explained_variance"
   },
   "outputs": [],
   "source": "pca = PCA()\npca.fit(continuous_var_scaled)\n\nexplained = pca.explained_variance_ratio_\n\nev = pd.DataFrame({\n    'PC': [f'PC{i+1}' for i in range(len(explained))],\n    'Explained Variance Ratio': explained\n})\nev",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad6329ca-5e77-4bff-8679-184d0809c7d1",
   "metadata": {
    "language": "python",
    "name": "scree_plot"
   },
   "outputs": [],
   "source": "# Scree plot (variance explained by each PC)\nplt.figure(figsize=(6,4))\nplt.plot(range(1, len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_, marker='o')\nplt.title('Scree Plot: Explained Variance by Principal Component')\nplt.xlabel('Principal Component')\nplt.ylabel('Proportion of Variance Explained')\nplt.xticks(range(1, len(pca.explained_variance_ratio_)+1))\nplt.grid(True, linestyle='--', linewidth=0.5)\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70c9fc6e-c4af-4cda-8c1c-9be4b7cdfc3a",
   "metadata": {
    "language": "python",
    "name": "calculate_loadings"
   },
   "outputs": [],
   "source": "# Loadings = eigenvectors of covariance of standardized data\nloadings = pd.DataFrame(\n    pca.components_.T,\n    index=continuous_var.columns,\n    columns=[f'PC{i+1}' for i in range(len(continuous_var.columns))]\n)\nloadings",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "548c222a-3f75-4dd4-ba27-bde6c086a37e",
   "metadata": {
    "name": "pca_summary",
    "collapsed": false
   },
   "source": "The first few principal components explain most of the meaningful variation in the construction projects data. Each component represents a different underlying pattern in how projects perform and relate to one another:\n1. PC1 – Project Efficiency: This component loads heavily on cost_overrun_pct and time_overrun_pct and slightly on scope_complexity, showing that more complex projects tend to go over budget and schedule.\n2. PC2 – Customer Relationships: Driven by prior_relationship_years, next12mo_spend, and customer_satisfaction, this captures the strength of ongoing client relationships and how satisfaction connects to future spending.\n3. PC3 – Project Complexity & Change: Influenced by scope_complexity and n_change_orders, it reflects how more complex projects often experience more scope adjustments during execution.\n4. PC4 – Project Scale: Aligned with project_size_usd and customer_satisfaction, suggesting that larger projects have different satisfaction dynamics compared to smaller ones."
  },
  {
   "cell_type": "markdown",
   "id": "4476f172-62f3-4d30-b383-5fdc30312384",
   "metadata": {
    "name": "num_4",
    "collapsed": false
   },
   "source": "#### 4. Project original data onto the necessary principle components"
  },
  {
   "cell_type": "code",
   "id": "ef094efd-4ba4-49fc-b9e3-ab94929c02d1",
   "metadata": {
    "language": "python",
    "name": "project_PCs"
   },
   "outputs": [],
   "source": "pc_scores = pca.transform(continuous_var_scaled)\n\npc_df = pd.DataFrame(pc_scores, columns=[f'PC{i+1}' for i in range(pc_scores.shape[1])])\n\npc_df_4 = pc_df[['PC1','PC2','PC3','PC4']]\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set(style=\"whitegrid\", context=\"notebook\")\npairplot = sns.pairplot(pc_df_4, diag_kind='kde', plot_kws={'alpha':0.6, 's':50, 'edgecolor':'k'})\npairplot.fig.suptitle('Pairwise Plots of PC1–PC4', y=1.02)\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3821a87f-4bec-414b-8b81-c1a06ff9aaff",
   "metadata": {
    "name": "plot_analysis",
    "collapsed": false
   },
   "source": "When plotting the first few principal components, the projects all cluster near the origin with no strong separation or noticeable outliers. This indicates that the continuous project variables (like size, schedule performance, and satisfaction) vary somewhat consistently across projects, without distinct groupings or extreme cases. In other words, the main sources of variation in the data are relatively balanced rather than being driven by one or two standout dimensions."
  },
  {
   "cell_type": "markdown",
   "id": "a9038e9b-09b1-4029-9048-2789633bd84b",
   "metadata": {
    "name": "num_5",
    "collapsed": false
   },
   "source": "#### 5. Explain in detail what the PCA has told you about the data, given the principal components some intuitive meaning, and explain how you would use your insights from the PCA.\n\n-------\n\nThe PCA results show that the projects in this dataset are pretty similar overall, with no clear clusters or big outliers when looking at the first few components. This means the continuous variables like project size, overruns, satisfaction, and change orders vary in a fairly consistent way across projects without any strong patterns or distinct groups. The variation that does exist is spread across several smaller factors instead of being driven by one main source.\n\nThe first four principal components represent the main themes in the data. PC1 captures overall project inefficiency, mainly tied to cost and time overruns. PC2 reflects the strength of customer relationships and future spend. PC3 shows scope volatility, with more change orders and complexity usually linked to lower satisfaction, while PC4 separates larger projects that have high satisfaction but shorter prior relationships.\n\nOverall, the PCA suggests that most projects perform similarly, but improving cost and time control (PC1) and managing scope changes (PC3) could make the biggest difference. The components could also be used as simplified inputs for modeling or for tracking project performance and relationship health over time."
  }
 ]
}